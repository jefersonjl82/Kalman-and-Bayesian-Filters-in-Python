{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "features_v02.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jefersonjlima/Kalman-and-Bayesian-Filters-in-Python/blob/master/features_v02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x55fp8Zfnnon",
        "colab_type": "text"
      },
      "source": [
        "# Intro\n",
        "\n",
        "This code convert [MITDB](https://physionet.org/physiobank/database/mitdb/) to Quoretech Dataset Format.\n",
        "\n",
        "Colab version code.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OXj0EKWofpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install packages\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    import wfdb as wf\n",
        "except:\n",
        "    !pip install wfdb==1.3.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d_PQIsOmmgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from scipy.signal import firwin, filtfilt, resample_poly, resample\n",
        "import wfdb as wf\n",
        "import math\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACSzt-VxpHpx",
        "colab_type": "text"
      },
      "source": [
        "# MIT Annotation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUWMD6oYmmgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Beat annotations:\n",
        "# Code\t\tDescription\n",
        "\n",
        "beatList = \\\n",
        "'''N\t\tNormal beat\n",
        "L\t\tLeft bundle branch block beat\n",
        "R\t\tRight bundle branch block beat\n",
        "B\t\tBundle branch block beat (unspecified)\n",
        "A\t\tAtrial premature beat\n",
        "a\t\tAberrated atrial premature beat\n",
        "J\t\tNodal (junctional) premature beat\n",
        "S\t\tSupraventricular premature or ectopic beat (atrial or nodal)\n",
        "V\t\tPremature ventricular contraction\n",
        "r\t\tR-on-T premature ventricular contraction\n",
        "F\t\tFusion of ventricular and normal beat\n",
        "e\t\tAtrial escape beat\n",
        "j\t\tNodal (junctional) escape beat\n",
        "n\t\tSupraventricular escape beat (atrial or nodal)\n",
        "E\t\tVentricular escape beat\n",
        "/\t\tPaced beat\n",
        "f\t\tFusion of paced and normal beat\n",
        "Q\t\tUnclassifiable beat\n",
        "~\t\tChange in signal quality\n",
        "?\t\tBeat not classified during learning'''\n",
        "\n",
        "\n",
        "# Non-beat annotations:\n",
        "# Code\t\tDescription\n",
        "noBeatList = \\\n",
        "'''[\t\tStart of ventricular flutter/fibrillation\n",
        "!\t\tVentricular flutter wave\n",
        "]\t\tEnd of ventricular flutter/fibrillation\n",
        "x\t\tNon-conducted P-wave (blocked APC)\n",
        "(\t\tWaveform onset\n",
        ")\t\tWaveform end\n",
        "p\t\tPeak of P-wave\n",
        "t\t\tPeak of T-wave\n",
        "u\t\tPeak of U-wave\n",
        "`\t\tPQ junction\n",
        "'\t\tJ-point\n",
        "^\t\t(Non-captured) pacemaker artifact\n",
        "|\t\tIsolated QRS-like artifact [1]\n",
        "~\t\tChange in signal quality [1]\n",
        "+\t\tRhythm change [2]\n",
        "s\t\tST segment change [2]\n",
        "T\t\tT-wave change [2]\n",
        "*\t\tSystole\n",
        "D\t\tDiastole\n",
        "=\t\tMeasurement annotation [2]\n",
        "\"\t\tComment annotation [2]\n",
        "@\t\tLink to external data [3]'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q36fxfqtmmgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beatTable = np.array([lst.split('\\t\\t') for lst in beatList.split('\\n')])\n",
        "noBeatTable = np.array([lst.split('\\t\\t') for lst in noBeatList.split('\\n')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4SvmfoWmmg2",
        "colab_type": "text"
      },
      "source": [
        "# QRS Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qofQMspommg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ecgDataFrame:\n",
        "    '''\n",
        "    create QRS Frames\n",
        "    '''\n",
        "    def __init__(self, path):\n",
        "        def exam_name(value):\n",
        "            sample = os.path.splitext(os.path.basename(value))[0]\n",
        "            patch = os.path.dirname(value)    \n",
        "            return sample, patch\n",
        "\n",
        "        sample, patch = exam_name(path)  \n",
        "        self._patch = patch\n",
        "        self._sample = sample\n",
        "        self.getSignal()\n",
        "\n",
        "    def getSignal(self):\n",
        "        _record = wf.rdsamp(self._patch + '/' + self._sample)\n",
        "\n",
        "        self.fs = 200\n",
        "        self.resampleFactor = 200 / _record.fs\n",
        "        self.signal1 = resample_poly(_record.p_signals[:,0] , \\\n",
        "                                        int(_record.siglen * self.resampleFactor), _record.siglen)\n",
        "        self.signal2 = resample_poly(_record.p_signals[:,1] , \\\n",
        "                                        int(_record.siglen * self.resampleFactor), _record.siglen)\n",
        "\n",
        "        self.siglen = self.signal1.size\n",
        "        self.signame = _record.signame\n",
        "\n",
        "        _ann = wf.rdann(self._patch + '/' + self._sample, 'atr')\n",
        "        self.annot = []\n",
        "        self.annotSamp = []\n",
        "\n",
        "        # excluded noise and rhythm marker\n",
        "        for idx, an in enumerate(_ann.symbol):\n",
        "            if an in beatTable[:,0]:\n",
        "                self.annot.append(an)\n",
        "                self.annotSamp.append(int(_ann.sample[idx] * self.resampleFactor))\n",
        "        self.annlen = len(self.annot)\n",
        "\n",
        "    def createDataFrame(self, sig , nsig, dblist, QRSlen):\n",
        "\n",
        "        df = pd.DataFrame()\n",
        "        symbLen = len(self.annot)\n",
        "\n",
        "        for idx,ann in enumerate(self.annot):\n",
        "            rr_coefLast = []\n",
        "            annot_last =  []\n",
        "            annot_mse =  []\n",
        "            p0 = self.annotSamp[idx]\n",
        "            if (idx-1) >= 0:\n",
        "                p0_last = self.annotSamp[idx-1]\n",
        "            else:\n",
        "                p0_last = self.annotSamp[idx]\n",
        "            left_values = math.ceil(1/3*QRSlen)\n",
        "            ritght_values = math.floor(2/3*QRSlen)\n",
        "                                    \n",
        "            if ((p0-left_values) >= 0) and ((p0+ritght_values) < self.siglen):\n",
        "                # create historic of RR interval posteriori\n",
        "                \n",
        "                if   self.annot[idx] == 'V' and self.annot[idx-1] == 'V':\n",
        "                    self.annot[idx] = 'VC'\n",
        "                elif self.annot[idx] == 'V' and self.annot[idx-1] == 'VC':\n",
        "                    self.annot[idx] = 'VT'\n",
        "                elif self.annot[idx] == 'V' and self.annot[idx-1] == 'VT':\n",
        "                    self.annot[idx] = 'VT'\n",
        "                \n",
        "                if   self.annot[idx] == 'S' and self.annot[idx-1] == 'S':\n",
        "                    self.annot[idx] = 'SC'\n",
        "                elif self.annot[idx] == 'S' and self.annot[idx-1] == 'SC':\n",
        "                    self.annot[idx] = 'STVA'\n",
        "                elif self.annot[idx] == 'S' and self.annot[idx-1] == 'STVA':\n",
        "                    self.annot[idx] = 'STVA'\n",
        "                \n",
        "                # test it rr_coeff +-5\n",
        "                for i in range(0,-5,-1):\n",
        "                    if ((idx-1+i) >= 0) and ((idx+1+i) < self.annlen):\n",
        "                        rr_coefLast.append((self.annotSamp[idx+i]-self.annotSamp[idx-1+i])/\n",
        "                                          (self.annotSamp[idx+1+i] - self.annotSamp[idx+i]))\n",
        "                        annot_last.append(self.annot[idx-1+i])\n",
        "                    else:\n",
        "                        rr_coefLast.append(np.random.rand())\n",
        "                        annot_last.append('~')\n",
        "                    \n",
        "                # get features\n",
        "                avg_sig = sig[(p0-left_values):(p0+ritght_values)]\n",
        "                avg_sig = avg_sig - np.mean(avg_sig)\n",
        "                \n",
        "                if (p0_last-left_values) > 0:\n",
        "                    \n",
        "                    # estimate qrs size\n",
        "                    qrs_left = 10\n",
        "                    qrs_right = 20\n",
        "                    last_beat = sig[(p0_last-qrs_left):(p0_last+qrs_right)]\n",
        "                    last_beat = last_beat - last_beat.min()\n",
        "                    last_beat = last_beat/last_beat.max()\n",
        "                    last_beat = last_beat - np.mean(last_beat)\n",
        "                    now_beat  = sig[(p0-qrs_left):(p0+qrs_right)]\n",
        "                    now_beat  = now_beat - now_beat.min()\n",
        "                    now_beat  = now_beat/now_beat.max()\n",
        "                    now_beat  = now_beat - np.mean(now_beat)\n",
        "                    # mse\n",
        "                    annot_mse = (np.square(now_beat - last_beat)).mean(axis=0)\n",
        "                else:\n",
        "                    annot_mse = 0\n",
        "                    \n",
        "                df = df.append({\n",
        "                    'signal':   pd.Series(avg_sig),\n",
        "                    'annot':    self.annot[idx], \n",
        "                    'signame':  self.signame[0],\n",
        "                    'nsig':     nsig,\n",
        "                    'sample':   dblist,\n",
        "                    'rr_coefLast': rr_coefLast,\n",
        "                    'annot_last': annot_last,\n",
        "                    'annot_mse': annot_mse,\n",
        "                    'index': idx\n",
        "                }, ignore_index=True)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "    def proj_fir(self,sig, low, high, npoles):\n",
        "        poles = firwin(npoles, [low/(self.fs/2), high/(self.fs/2)], pass_zero=False)\n",
        "        return filtfilt(poles, 1.0, sig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34jRxSYemmg5",
        "colab_type": "text"
      },
      "source": [
        "# Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh544XSNqg2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Select Database\n",
        "\n",
        "dataset = 'mitdb' #@param [\"mitdb\", \"ahadb\", \"svdb\"] \n",
        "\n",
        "\n",
        "if dataset is 'svdb':\n",
        "    patch = dataset + '/'\n",
        "    leads = ['ECG1', 'ECG2']\n",
        "    if os.path.exists(patch):\n",
        "        print('SVDB Exist')\n",
        "    else:\n",
        "        # Copy SVDB database\n",
        "        !wget -r -np 'https://physionet.org/physiobank/database/svdb/'\n",
        "        !mv ./physionet.org/physiobank/database/svdb/ ./\n",
        "        !rm -r ./physionet.org/    \n",
        "\n",
        "elif dataset is 'ahadb':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    patch = '/content/drive/My Drive/MyDatasets/' + dataset + '/'\n",
        "    leads = ['ECG0', 'ECG1']\n",
        "\n",
        "elif dataset is 'mitdb':\n",
        "    patch = dataset + '/'\n",
        "    leads = ['MLII', 'V5']\n",
        "    if os.path.exists(patch):\n",
        "        print('MITDB Exist')\n",
        "    else:\n",
        "        # Copy MIT database\n",
        "        !wget -r -np 'http://www.physionet.org/physiobank/database/mitdb/'\n",
        "        !mv ./www.physionet.org/physiobank/database/mitdb/ ./\n",
        "        !rm -r ./www.physionet.org/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPBu-Hrxmmg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "listRecords = glob.glob(patch + '*.dat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTdK1YcQmmg9",
        "colab_type": "text"
      },
      "source": [
        "### Extract Transform Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTrmrax_e6_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Filter Design\n",
        "df = pd.DataFrame()\n",
        "\n",
        "for dblist in listRecords:\n",
        "    print(\"File: %s\"%(dblist))\n",
        "    data = ecgDataFrame(dblist)\n",
        "    print(Counter(data.annot))\n",
        "    print(data.signame)\n",
        "    \n",
        "    poles = 50\n",
        "    hfilter = 0.67 #@param {type:\"slider\", min:0.67, max:5, step:0.01}\n",
        "    lfilter = 40   #@param {type:\"slider\", min:30, max:100, step:1}\n",
        "    filter_enable = True #@param {type:\"boolean\"}\n",
        "    \n",
        "    if  not (True in np.isnan(data.signal1)) or (True in np.isnan(data.signal2)):\n",
        "        if leads[0] in data.signame:\n",
        "            if data.signame.index(leads[0]):\n",
        "                nsig = 1\n",
        "                if filter_enable:\n",
        "                    sig = data.proj_fir(data.signal2, hfilter, lfilter, poles)\n",
        "                else:\n",
        "                    sig = data.signal2\n",
        "            else:\n",
        "                nsig = 0\n",
        "                if filter_enable:\n",
        "                    sig = data.proj_fir(data.signal1, hfilter, lfilter, poles)\n",
        "                else:\n",
        "                    sig = data.signal1\n",
        "        elif leads[1] in data.signame:\n",
        "            if data.signame.index(leads[1]):\n",
        "                nsig = 1\n",
        "                if filter_enable:\n",
        "                    sig = data.proj_fir(data.signal2, hfilter, lfilter, poles)\n",
        "                else:\n",
        "                    sig = data.signal2\n",
        "            else:\n",
        "                nsig = 0\n",
        "                if filter_enable:\n",
        "                    sig = data.proj_fir(data.signal1, hfilter, lfilter, poles)\n",
        "                else:\n",
        "                    sig = data.signal1\n",
        "        qrsFrame = 140 #@param {type:\"slider\", min:100, max:200, step:1}\n",
        "        df = df.append(data.createDataFrame(sig, nsig, dblist, qrsFrame))\n",
        "        df = df.reset_index(drop=True)\n",
        "        print(df.index)\n",
        "        print(Counter(df['annot']))\n",
        "    else:\n",
        "        print('Nan')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35lcOxqV3p0o",
        "colab_type": "text"
      },
      "source": [
        "### QRS Windows Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJASk4iZ0PUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def foo(x):\n",
        "    if x[0] < 0.8:\n",
        "        return -1\n",
        "    elif x[0] > 0.8 and x[0] < 1.2:\n",
        "        return 0\n",
        "    elif x[0] > 1.2:\n",
        "        return 1\n",
        "    \n",
        "df['preco'] = df.rr_coefLast.apply(foo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Alwmbkt73cU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def foo2(x):\n",
        "    x = np.asarray(x, dtype=np.float32)\n",
        "    out = x\n",
        "    select = x < 0.8\n",
        "    out[select] = -1\n",
        "    select = np.logical_and(x > 0.8, x < 1.2)\n",
        "    out[select] = 0\n",
        "    select = x > 1.2\n",
        "    out[select] = 1\n",
        "    return out\n",
        "\n",
        "df['rr_coefLast_hot'] = df['rr_coefLast'].apply(foo2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MYDkuiEAMbZ",
        "colab_type": "text"
      },
      "source": [
        "# Save model in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLV-ucfuxG9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_name = dataset + '_' + str(qrsFrame) + '_' +  str(poles) + '_' + str(filter_enable) + '_rhythm_{}.pkl'.format(datetime.date.today())\n",
        "df.to_pickle('drive/My Drive/MyDatasets/'+ file_name, protocol=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8ogEYjmI5C7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}